{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d29d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.sql.types import LongType, DoubleType\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import time\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1db5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"spark://master:7077\").config(\"spark.executor.memory\", \"6gb\").appName(\"Naive Bayes\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['labels']\n",
    "for i in range(1, 1025):\n",
    "    columns.append(\"f\" + str(i))\n",
    "df = spark.read.format('csv').options(header='true').load('/MLInput_u/MLInput_u.csv') \n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808007e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "\n",
    "df = convertColumn(df, columns, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "df_new = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "# standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "# scaler = standardScaler.fit(df_new)\n",
    "# scaled_df = scaler.transform(df_new)\n",
    "\n",
    "# scaled_df.take(2)\n",
    "# scaled_df.printSchema()\n",
    "# scaled_df.show()\n",
    "\n",
    "#without scaling\n",
    "scaled_df = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f118fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = scaled_df.withColumn(\"label\", predictions[\"label\"].cast(\"double\")).randomSplit([.7,.3],seed=1234)\n",
    "rddTrain = train_data.rdd.map(lambda row: LabeledPoint(row['label'], row['features'].toArray()))\n",
    "rddTest = test_data.rdd.map(lambda row: LabeledPoint(row['label'], row['features'].toArray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cab319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "lr = LogisticRegressionWithLBFGS(labelCol=\"label\", featuresCol=\"features\")\n",
    "nbparamGrid = (ParamGridBuilder().build())\n",
    "nbevaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "nbcv = CrossValidator(estimator = lr,\n",
    "                    estimatorParamMaps = nbparamGrid,\n",
    "                    evaluator = nbevaluator,\n",
    "                    numFolds = 10)\n",
    "nbcvModel = nbcv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nbcvModel.transform(test_data)\n",
    "print('Accuracy:', nbevaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "predictions_rdd = predictions.withColumn(\"label\", predictions[\"label\"].cast(\"double\")).rdd.map(lambda r: (r.prediction, r.label))\n",
    "metrics = MulticlassMetrics(predictions_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % metrics.precision())\n",
    "print(\"Recall = %s\" % metrics.recall())\n",
    "print(\"F1 Score = %s\" % metrics.fMeasure())\n",
    "print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c779577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60036c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
